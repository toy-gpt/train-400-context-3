# ============================================================
# SE_MANIFEST.toml (Repository Intent, Scope, and Role)
# ============================================================

schema = "se-manifest-1"
schema_url = "https://github.com/structural-explainability/spec-se/blob/main/manifests/se-manifest-1.md"

[meta]
framework = "Structural Explainability"
framework_url = "https://github.com/structural-explainability"
framework_note = "Provides definitions and conventions for SE_MANIFEST semantics."
description = "Declarative claim of repository intent, scope, and role."
purpose = "To make explicit the boundaries, responsibilities, and expectations of this repository relative to others."
keywords_note = "Keywords live only in CITATION.cff (canonical)."

[repo]
name = "train-400-context-3"
org = "toy-gpt"
kind = "software"
status = "academic"
since = "2026"
summary = "Toy language model training: next-token predictor (3-token context window)."

[training]
capability = "unigram"
context_window = 3
architecture = "softmax regression over vocabulary (toy scale)"
task = "next-token prediction"

[observation]
corpus_id = "000"
corpus_name = "tiny_cat_dog"
corpus_path = "corpus/000_cat_dog.txt"
corpus_note = "Deliberately minimal corpus to make the learning loop inspectable."

[artifact]
pretrained = true
artifact_dir = "artifacts"
artifacts_expected = [
  "artifacts/00_meta.json",
  "artifacts/01_vocabulary.csv",
  "artifacts/02_model_weights.csv",
  "artifacts/03_token_embeddings.csv",
]
evidence_expected = [
  "outputs/train_log.csv",
]

[layer]
space = "Machine Learning"
role = "post-secondary-education"

[depends]
required = [
  "python>=3.14",
  "uv",
  "git",
]
optional = [
  "mkdocs",
  "ruff",
  "pyright",
  "pytest",
  "lychee",
]

[provides]
artifacts = [
  "ANNOTATIONS.md",
  "CITATION.cff",
  "LICENSE",
  "README.md",
  "SE_MANIFEST.toml",
  "SETUP.md",
]

[scope]
includes = [
  "basic Git workflows (clone, commit, push, pull)",
  "use a local Python virtual environment (.venv) managed by uv",
  "manage dependencies via pyproject.toml and uv",
  "use external packages for logging and diagnostics",
  "use professional IDE-based development workflows",
  "train a toy next-token prediction model on a declared corpus",
"export inspectable pretrained model artifacts for downstream use",
]
excludes = [
  "production deployment systems",
  "claims of semantic understanding or factual correctness",
  "high-stakes decision support",
  "training large-scale foundation models",
]

[citation]
cff = "CITATION.cff"
preferred = "repo"

[traceability]
identifier_map = "none"
